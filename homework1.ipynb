{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3fa14c-4408-4850-bf85-4e1b145e87e3",
   "metadata": {},
   "source": [
    "### BATINA AGASA\n",
    "#### Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a639b4-b980-445c-a651-7ef3bdf3568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [17:49<00:00, 356.54s/it]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feedparser'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7540/295501940.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'feedparser'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from lxml import etree\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "def xml_to_dict(tree, paths=None, nsmap=None, strip_ns=False):\n",
    "    \"\"\"Convert an XML tree to a dictionary.\n",
    "    :param tree: etree Element\n",
    "    :type tree: :class:`lxml.etree._Element`\n",
    "    :param paths: An optional list of XPath expressions applied on the XML tree.\n",
    "    :type paths: list[basestring]\n",
    "    :param nsmap: An optional prefix-namespace mapping for conciser spec of paths.\n",
    "    :type nsmap: dict\n",
    "    :param strip_ns: Flag for whether to remove the namespaces from the tags.\n",
    "    :type strip_ns: bool\n",
    "    \"\"\"\n",
    "    paths = paths or ['.//']\n",
    "    nsmap = nsmap or {}\n",
    "    fields = defaultdict(list)\n",
    "    for path in paths:\n",
    "        elements = tree.findall(path, nsmap)\n",
    "        for element in elements:\n",
    "            tag = re.sub(\n",
    "                r'\\{.*\\}', '', element.tag) if strip_ns else element.tag\n",
    "            fields[tag].append(element.text)\n",
    "    return dict(fields)\n",
    "\n",
    "sets = [\"physics\",\"econ\",\"cs\"]\n",
    "XMLParser = etree.XMLParser(remove_blank_text=True, recover=True, resolve_entities=False)\n",
    "\n",
    "\n",
    "for set_ in tqdm.tqdm(sets):\n",
    "    response = requests.get(\"http://export.arxiv.org/oai2?verb=ListIdentifiers&set={}&from=2020-01-01&metadataPrefix=oai_dc\".format(set_))\n",
    "    tree = etree.XML(response.content, parser=XMLParser)\n",
    "    papers = xml_to_dict(tree=tree)\n",
    "    ids = [id_.split(\":\")[-1] for id_ in papers[\"{http://www.openarchives.org/OAI/2.0/}identifier\"]]\n",
    "    arxiv_txt = open(r'C:\\Users\\ferve\\Documents\\NoSQL\\Homeworks\\arxiv_db.txt', 'a')\n",
    "    [arxiv_txt.write(id_ + \"\\n\") for id_ in ids]\n",
    "    arxiv_txt.close()\n",
    "    if len(papers) == 7:\n",
    "        time.sleep(25)\n",
    "        continue\n",
    "    token = papers[\"{http://www.openarchives.org/OAI/2.0/}resumptionToken\"][0]\n",
    "    time.sleep(25)\n",
    "    done = False\n",
    "    while done == False:\n",
    "            response = requests.get(\"http://export.arxiv.org/oai2?verb=ListIdentifiers&resumptionToken={}\".format(token))\n",
    "            tree = etree.XML(response.content, parser=XMLParser)\n",
    "            papers = xml_to_dict(tree=tree)\n",
    "            ids = [id_.split(\":\")[-1] for id_ in papers[\"{http://www.openarchives.org/OAI/2.0/}identifier\"]]\n",
    "            if len(ids) != 10000:\n",
    "                done = True\n",
    "            arxiv_txt = open(r'C:\\Users\\ferve\\Documents\\NoSQL\\Homeworks\\arxiv_db.txt', 'a')\n",
    "            [arxiv_txt.write(id_ + \"\\n\") for id_ in ids]\n",
    "            arxiv_txt.close()\n",
    "            if len(papers) == 7:\n",
    "                done = True\n",
    "            else:\n",
    "                token = papers[\"{http://www.openarchives.org/OAI/2.0/}resumptionToken\"][0]\n",
    "            time.sleep(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750537cf-d9b1-446d-a280-a38a81dca39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 217799/408542 [1:32:26<1:20:57, 39.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7540/2666927726.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mids_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "import tqdm\n",
    "import time\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = client[\"Homeworks_2\"]\n",
    "collection = mydb[\"Homework2\"]\n",
    "\n",
    "\n",
    "with open(r'C:\\Users\\ferve\\Documents\\NoSQL\\Homeworks\\arxiv_db.txt',\"r\") as lines:\n",
    "    ids = lines.read().split(\"\\n\")[0:-2]\n",
    "\n",
    "results = {}\n",
    "ids_query = []\n",
    "iteration = 1\n",
    "\n",
    "for id_ in tqdm.tqdm(ids):\n",
    "    if iteration % 100 != 0:\n",
    "        iteration += 1\n",
    "        ids_query.append(id_)\n",
    "    else:\n",
    "        ids_query = \",\".join(ids_query)\n",
    "        response = requests.get('http://export.arxiv.org/api/query?id_list={}&max_results=100'.format(ids_query))\n",
    "        feed = feedparser.parse(response.content)\n",
    "        list_of_insertion = []\n",
    "        for entry in feed.entries:\n",
    "            list_of_insertion.append(dict(entry))\n",
    "        collection.insert_many(list_of_insertion)\n",
    "        ids_query = []\n",
    "        iteration = 1\n",
    "        time.sleep(1/3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c74cfa0-c70a-4034-b10d-031412acec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import requests\n",
    "import feedparser\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = client[\"Homeworks_2\"]\n",
    "collection = mydb[\"Homework2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217eac3-741c-49d0-95d2-ff2e18bab4cf",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafbda1d-e077-4bdf-b216-09a37da5c002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'author_-1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.create_index([ (\"author\",-1) ]) # on a fait un index sur la variable autheur, le -1 correcpond au plus vieux au plus jeune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54912546-3cd4-4df8-81ab-f7d7771a3f03",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529e67ad-ff3f-449e-86c1-ea15e68b6ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fervent= collection.count_documents(\n",
    "    {\n",
    "        'published' : \n",
    "        {'$not' : \n",
    "         {'$regex' : \".*2019.*|.*2020.*|.*2021.*|.*2018.*|.*2017.*|.*2016.*|.*2015.*|.*2022.*\"}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(fervent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3abeee-3c0f-47f4-82da-50b917ca8f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x1a914de8680>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nous supprimerons les élements (delete_many) qui ne contiennent pas les années 2015.\n",
    "\n",
    "\n",
    "collection.delete_many(\n",
    "    {\n",
    "        'published' : \n",
    "        {'$not' : \n",
    "         {'$regex' : \".*2015.*|.*2016.*|.*2017.*|.*2018.*|.*2019.*|.*2020.*|.*2021.*|.*2022.*\"}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "#On a pu supprimer 3151 éléments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3fe89-c09f-432e-8592-13b5bf363798",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255bb19c-1028-4e6a-94a9-16e8b571697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 27168 documents comportant un seul auteur\n",
      "Il y'a 42887 documents comportant deux auteurs\n"
     ]
    }
   ],
   "source": [
    "# Avec seul auteur\n",
    "\n",
    "doc_avec_1auth = collection.count_documents({\"authors\" :{\"$size\":1}})\n",
    "print(\"Il y'a \" + str(doc_avec_1auth) + \" documents comportant un seul auteur\")\n",
    "\n",
    " # Avec deux auteurs\n",
    "doc_avec_2auth = collection.count_documents({\"authors\" :{\"$size\":2}})\n",
    "print(\"Il y'a \" + str(doc_avec_2auth) +\" documents comportant deux auteurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d715d3-6847-44cc-9a7d-ec73927271a3",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96dcc213-bf27-4147-b7e6-effae96adc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('6261b5c41f507438547e6915'), 'id': 'http://arxiv.org/abs/1501.00434v2', 'guidislink': True, 'link': 'http://arxiv.org/abs/1501.00434v2', 'updated': '2016-01-12T19:33:34Z', 'updated_parsed': [2016, 1, 12, 19, 33, 34, 1, 12, 0], 'published': '2015-01-02T16:31:20Z', 'published_parsed': [2015, 1, 2, 16, 31, 20, 4, 2, 0], 'title': 'Monetary Policy and Dark Corners in a stylized Agent-Based Model', 'title_detail': {'type': 'text/plain', 'language': None, 'base': '', 'value': 'Monetary Policy and Dark Corners in a stylized Agent-Based Model'}, 'summary': 'We extend in a minimal way the stylized model introduced in in \"Tipping\\nPoints in Macroeconomic Agent Based Models\" [JEDC 50, 29-61 (2015)], with the\\naim of investigating the role and efficacy of monetary policy of a `Central\\nBank\\' that sets the interest rate such as to steer the economy towards a\\nprescribed inflation and employment level. Our major finding is that provided\\nits policy is not too aggressive (in a sense detailed in the paper) the Central\\nBank is successful in achieving its goals. However, the existence of different\\nequilibrium states of the economy, separated by phase boundaries (or \"dark\\ncorners\"), can cause the monetary policy itself to trigger instabilities and be\\ncounter-productive. In other words, the Central Bank must navigate in a narrow\\nwindow: too little is not enough, too much leads to instabilities and wildly\\noscillating economies. This conclusion strongly contrasts with the prediction\\nof DSGE models.', 'summary_detail': {'type': 'text/plain', 'language': None, 'base': '', 'value': 'We extend in a minimal way the stylized model introduced in in \"Tipping\\nPoints in Macroeconomic Agent Based Models\" [JEDC 50, 29-61 (2015)], with the\\naim of investigating the role and efficacy of monetary policy of a `Central\\nBank\\' that sets the interest rate such as to steer the economy towards a\\nprescribed inflation and employment level. Our major finding is that provided\\nits policy is not too aggressive (in a sense detailed in the paper) the Central\\nBank is successful in achieving its goals. However, the existence of different\\nequilibrium states of the economy, separated by phase boundaries (or \"dark\\ncorners\"), can cause the monetary policy itself to trigger instabilities and be\\ncounter-productive. In other words, the Central Bank must navigate in a narrow\\nwindow: too little is not enough, too much leads to instabilities and wildly\\noscillating economies. This conclusion strongly contrasts with the prediction\\nof DSGE models.'}, 'authors': [{'name': 'Stanislao Gualdi'}, {'name': 'Marco Tarzia'}, {'name': 'Francesco Zamponi'}, {'name': 'Jean-Philippe Bouchaud'}], 'author_detail': {'name': 'Jean-Philippe Bouchaud'}, 'author': 'Jean-Philippe Bouchaud', 'arxiv_doi': '10.1007/s11403-016-0174-z', 'links': [{'title': 'doi', 'href': 'http://dx.doi.org/10.1007/s11403-016-0174-z', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/1501.00434v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/1501.00434v2', 'rel': 'related', 'type': 'application/pdf'}], 'arxiv_comment': 'Contribution to the CRISIS project, 25 pages, 21 figures, pseudo-code\\n  of the model, revised and improved version', 'arxiv_journal_ref': 'Journal of Economic Interaction and Coordination 12, 507-537\\n  (2017)', 'arxiv_primary_category': {'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom'}, 'tags': [{'term': 'q-fin.EC', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'physics.soc-ph', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'q-fin.GN', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]}]\n"
     ]
    }
   ],
   "source": [
    "# On a juste pris le premier de la liste vu que MongoDB insère +1 aux id\n",
    "\n",
    "dernier = collection.find().sort(\"_id\", 1).limit(1)\n",
    "print(list(dernier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82d785-7197-4d1f-94f1-2c16724b4a14",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cdfa3be-1b42-49e8-bd48-dae64ce57640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 195 documents parlant de technology donc on va pas print sinon ça va flood.\n"
     ]
    }
   ],
   "source": [
    "q5 = collection.count_documents({'title': {'$regex' : \"technology\", \"$options\" : 'i' }})\n",
    "print(\"Il y'a \" + str(q5) + \" documents parlant de technology donc on va pas print sinon ça va flood.\")\n",
    "\n",
    "#for docs_sans_mesh in meshword_null :\n",
    "#    print(docs_sans_mesh)\n",
    "\n",
    "# il y'a 22065 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31da30-79bc-48e6-aafe-57390451ff19",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34285950-0881-4e59-bb89-8b4e2dd937fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 52055 documents sans arxiv_comment.\n"
     ]
    }
   ],
   "source": [
    "arxiv_comment_null = collection.count_documents({'arxiv_comment': None })\n",
    "print(\"Il y'a \" + str(arxiv_comment_null) + \" documents sans arxiv_comment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dcab2e-9f2e-46fd-bad3-5b4de75739db",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6f3fc6-5745-4f1d-937f-d89e743c7832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 204485 documents avec arxiv_affiliation.\n",
      "Il y'a 7986 documents sans arxiv_affiliation.\n"
     ]
    }
   ],
   "source": [
    "arxiv_affi = collection.count_documents({'arxiv_affiliation' : {'$not': {'$regex' : \"\"}}})\n",
    "print(\"Il y'a \" + str(arxiv_affi ) + \" documents avec arxiv_affiliation.\")\n",
    "\n",
    "arxiv_affi2 = collection.count_documents({'arxiv_affiliation' : {'$regex' : \"\"}})\n",
    "print(\"Il y'a \" + str(arxiv_affi2) + \" documents sans arxiv_affiliation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f129c1-b813-428f-8d75-b271f80ad784",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb5e13-60c2-4aa4-a766-f4f05cc5b00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 171278 documents sortis après 2019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "question_8 = collection.count_documents(\n",
    "    {\"published\":{\"$regex\" : \".*2021.*|.*2020.*|.*2022.*\"}})\n",
    "\n",
    "print(\"Il y'a \" + str(question_8) + \" documents sortis après 2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c5492-b9cf-4f8c-9d3c-b44b8979c11e",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda18228-c611-493f-9dfe-bd8fe711e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 110 documents avec China en arxiv_affiliation\n"
     ]
    }
   ],
   "source": [
    "question_9 = collection.count_documents({'arxiv_affiliation': {'$regex' : \".*China.*\", '$options' :'i' }})\n",
    "print(\"Il y'a \" + str(question_9) + \" documents avec China en arxiv_affiliation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d294927-1d3e-4da9-90e0-bf3efe55a4f7",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62cd4b5a-4c72-4958-9d62-fdd348f924fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x1a914d49c80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pray_the_stackoverflow_guy= collection.aggregate(\n",
    "    [\n",
    "        {\"$group\": {\"_id\": \"$id\", \"unique_ids\": {\"$addToSet\": \"$_id\"}, \"count\": {\"$sum\": 1}}},\n",
    "        {\"$match\": {\"count\": { \"$gte\": 2 }}}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = []\n",
    "for doc in pray_the_stackoverflow_guy:\n",
    "    del doc[\"unique_ids\"][1]\n",
    "    for id in doc[\"unique_ids\"]:\n",
    "        response.append(id)\n",
    "        \n",
    "collection.delete_many({\"_id\": {\"$in\": response}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e56ebd-b633-449c-87aa-be7630d22710",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abff571b-5981-4938-9977-b75b1255ee07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x1a914e12680>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.delete_many(\n",
    "    {\"summary\" : {\"$regex\" : '\\\"R.*'}})\n",
    "#211822\n",
    "#211746   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774ba19-74c4-47ff-9a9d-a563f20ba522",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2021b-b20e-494f-a482-93d9eebfebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "collection.count_documents({'title': {'$regex': \".*environment.*\", '$options': 'i' }})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
